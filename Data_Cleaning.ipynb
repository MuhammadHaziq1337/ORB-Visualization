{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'email_process.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "df.dropna(subset=['Subject'], inplace=True) \n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce') \n",
    "df.drop_duplicates(subset=['Body'], inplace=True) \n",
    "\n",
    "\n",
    "df['Subject'] = df['Subject'].str.lower()\n",
    "df['Body'] = df['Body'].str.lower()\n",
    "\n",
    "\n",
    "df['Subject'] = df['Subject'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "df['Body'] = df['Body'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n",
    "\n",
    "\n",
    "df['From_Domain'] = df['From'].str.extract(r'@(\\w+\\.\\w+)')\n",
    "df['To_Domain'] = df['To'].str.extract(r'@(\\w+\\.\\w+)')\n",
    "\n",
    "\n",
    "df['Weekday'] = df['Date'].dt.day_name()\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "\n",
    "columns_to_drop = ['X-Folder', 'X-Origin', 'X-Filename']  \n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv('2_email_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.7 GiB for an array with shape (227212,) and data type <U32759",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muham\\Desktop\\DAV PROJ\\Data_Cleaning.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# For LDA, we need to convert the email bodies to a bag-of-words model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m count_vect \u001b[39m=\u001b[39m CountVectorizer(max_df\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m, min_df\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, stop_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m doc_term_matrix \u001b[39m=\u001b[39m count_vect\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39;49m\u001b[39mBody\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mU\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Create and fit the LDA model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m lda \u001b[39m=\u001b[39m LatentDirichletAllocation(n_components\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 27.7 GiB for an array with shape (227212,) and data type <U32759"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('2_email_data.csv')\n",
    "\n",
    "# For LDA, we need to convert the email bodies to a bag-of-words model\n",
    "count_vect = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(df['Body'].values.astype('U'))\n",
    "\n",
    "# Create and fit the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "# Retrieve the words per topic\n",
    "words = count_vect.get_feature_names()\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"Top words for topic {i}:\")\n",
    "    print([words[i] for i in topic.argsort()[-10:]])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muham\\Desktop\\DAV PROJ\\Data_Cleaning.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(X\u001b[39m.\u001b[39mtext, X\u001b[39m.\u001b[39mlabel_) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Apply NER to the 'Body' of emails\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mnamed_entities\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mBody\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(named_entity_recognition)\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4523\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4525\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\muham\\Desktop\\DAV PROJ\\Data_Cleaning.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnamed_entity_recognition\u001b[39m(text):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(X\u001b[39m.\u001b[39mtext, X\u001b[39m.\u001b[39mlabel_) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments]\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\spacy\\language.py:999\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    979\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    980\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    983\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[0;32m    985\u001b[0m     \u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 999\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[0;32m   1000\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\spacy\\language.py:1093\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1092\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[1;32m-> 1093\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[1;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load Spacy's English tokenizer model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to apply NER\n",
    "def named_entity_recognition(text):\n",
    "    doc = nlp(text)\n",
    "    return [(X.text, X.label_) for X in doc.ents]\n",
    "\n",
    "# Apply NER to the 'Body' of emails\n",
    "df['named_entities'] = df['Body'].apply(named_entity_recognition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muham\\Desktop\\DAV PROJ\\Data_Cleaning.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(ent\u001b[39m.\u001b[39mtext, ent\u001b[39m.\u001b[39mlabel_) \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Apply NER on the 'Body' column\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mentities\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mBody\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(extract_entities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# View the entity extraction results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mentities\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mhead())\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4523\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4525\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\muham\\Desktop\\DAV PROJ\\Data_Cleaning.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_entities\u001b[39m(text):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muham/Desktop/DAV%20PROJ/Data_Cleaning.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [(ent\u001b[39m.\u001b[39mtext, ent\u001b[39m.\u001b[39mlabel_) \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments]\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\spacy\\language.py:999\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    979\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    980\u001b[0m     text: Union[\u001b[39mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    983\u001b[0m     component_cfg: Optional[Dict[\u001b[39mstr\u001b[39m, Dict[\u001b[39mstr\u001b[39m, Any]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    984\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Doc:\n\u001b[0;32m    985\u001b[0m     \u001b[39m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[39m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[39m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m    998\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 999\u001b[0m     doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_doc(text)\n\u001b[0;32m   1000\u001b[0m     \u001b[39mif\u001b[39;00m component_cfg \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m         component_cfg \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mf:\\Pythan\\lib\\site-packages\\spacy\\language.py:1093\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(doc_like, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1092\u001b[0m     \u001b[39mreturn\u001b[39;00m Doc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\u001b[39m.\u001b[39mfrom_bytes(doc_like)\n\u001b[1;32m-> 1093\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE1041\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc_like)))\n",
      "\u001b[1;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the pre-trained NER model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to extract entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Apply NER on the 'Body' column\n",
    "df['entities'] = df['Body'].apply(extract_entities)\n",
    "\n",
    "# View the entity extraction results\n",
    "print(df['entities'].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
